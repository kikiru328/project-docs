# ChatBot (feat. RAG)

> ⚠️ *해당 프로젝트는 기관 요청에 따라 코드 전체가 비공개(private) 처리되어 있으며, 구현 세부 내용은 README와 문서로만 제공됩니다.*

**국가교통기관 전용 법률 문서 기반 QA 시스템**  
`Blossom-8B` 기반의 LLM과 RAG 구조를 통합하여, 법률관련 질의에 대해 신뢰도 높은 응답을 자동 생성하는 온프레미스 챗봇 시스템입니다.


## 프로젝트 개요

**국가교통기관 내부의 방대한 법률 문서를 자동으로 이해하고 응답하는 질의응답 시스템** 
온프레미스 환경에서 `Blossom-8B`를 서빙하고, `RAG 구조`와 질문 분류기를 통합하여 사용자의 질의 의도에 맞는 정보를 검색, 응답을 제공합니다.

**모델 성능 보완, 응답 신뢰도 확보, 보안 준수**라는 세 가지 실무 요구를 해결하기 위해 기획되었으며,  
전체 파이프라인의 설계부터 구현, 배포까지 개발하였습니다.

## 프로젝트 배경 및 필요성

- 국가교통 기관은 법률, 기술지침, 운영 매뉴얼 등 **복잡하고 방대한 문서군**을 요구
- 기존 정보 시스템은 정형 쿼리/검색 중심 → **질문 맥락에 따른 탐색 불가**
- GPT-4 등 외부 LLM API는 **데이터 보안 상 사용 불가**

> **목표는 단순한 챗봇 구현이 아닌, 특화 도메인에서 작동 가능한 "신뢰 가능한 자동 질의응답 시스템" 구축이었습니다**

## 핵심 기술 구성

### 도식화
기술 도식화는 여기에서 참고바랍니다. [자세히 보기](Rail_GPT.pdf)

### 1. RAG 기반 질의응답 구조

- 내부 법률 문서를 Markdown 구조로 정제하고 문단 단위로 벡터화
- FAISS를 활용한 **문맥 유사도 기반 검색 인덱스 구축**
- 사용자 질문에 대해 유사도 상위 N개의 문서를 추출하여 LLM의 context로 삽입
- Blossom-8B가 답변을 생성할 때 **사전 검색된 문서를 기반으로 추론 가능하도록 설계**

### 2. 질문 분류기 및 응답 흐름 제어

- 모든 질의를 세 가지 유형으로 분류:  
  `law`, `related_general`, `general`
- Sentence-BERT 기반 분류기로 질문 표현 방식이 달라도 의미 기반 분류 가능
- RAG 적용 여부, 응답 스타일, 포맷이 유형별로 자동 분기
- 추가로 금칙어 기반 사전 필터링을 포함하여 **도메인 외 질문 차단 및 보안 대응**

### 3. 온프레미스 모델 서빙 환경

- Blossom-8B 모델을 **vLLM 기반 온프레미스 구조로 구성**
- Ollama 기반 프로토타입과 vLLM 환경을 병렬 지원 (실사용은 vLLM)
- Streamlit 내 `st.cache_resource`로 모델 재로딩 방지
- GPU 메모리 효율을 고려한 구성 및 예외 처리 적용


## 주요 구성 요소

| 컴포넌트 | 설명 |
|----------|------|
| 질문 분류기 | 질문 유형에 따라 처리 흐름 제어 |
| RAG Retriever | 문단 단위 유사 문서 검색 (FAISS + KoS-Roberta) |
| LLM Generator | Blossom-8B 또는 Ollama 기반 응답 생성 |
| 필터링 로직 | 민감 질문 차단 또는 지정 응답 제공 |
| WordCloud 분석기 | 사용 이력 기반 키워드 시각화 제공 |


## Demo
![image](https://github.com/user-attachments/assets/8a89ef15-dbee-4a86-bcdf-91affb3bb3b1)

> ⚠️ *기관 요청으로 인한 주제는 masking 되어 있으므로 양해 부탁드립니다.*

# 기술적 가치 및 기대효과

- 대규모 LLM 없어도 문맥 정밀도 높은 응답을 생성할 수 있는 구조 확립
- 도메인 지식과 사용자의 실질 질의 흐름을 연결하는 정형화된 Q&A 파이프라인 구현
- 실내망 전용 시스템 도입을 고려한 온프레미스 모델 설계와 데이터 보호 구조 완비
- 분류기 + 필터링 + 응답 포맷팅 등 보수적 응답 품질 통제를 위한 체계적 설계

